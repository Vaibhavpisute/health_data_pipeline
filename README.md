ðŸš€ Health and Insurance Data Analysis Project This project focuses on analyzing large-scale healthcare and insurance data using a big data architecture. It addresses the growing issue of fraudulent claims in the insurance sector by leveraging distributed data processing tools and scalable storage solutions.

The architecture is built on AWS and utilizes Apache Spark for data ingestion and transformation, with data stored in S3 and Hive/Redshift for querying and reporting. Airflow is used for workflow orchestration, enabling seamless scheduling and monitoring of data pipelines.

Key Features:
ETL pipelines developed using PySpark and Spark.
Data ingestion from Oracle-based RDBMS into Amazon S3.
Data transformation, quality assurance, and incremental load handling.
Query optimization using Hive and Spark best practices.
Automated reporting pipeline with scheduled job execution using Airflow.
Fraud detection and prescription/treatment trend analytics.

Tech Stack:
Apache Spark, PySpark, Hive, Redshift, HDFS
Apache Airflow for orchestration
AWS S3 for scalable storage
RDBMS (Oracle) as the source system

